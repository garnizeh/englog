# MVP-001: PostgreSQL Database Setup & Schema

**Feature:** MVP-INFRA
**Priority:** P0 (Critical)
**Effort:** Large (5 days)
**Dependencies:** None

## Objective

Migrate from in-memory storage to PostgreSQL with JSONB support, establishing the production database foundation for the MVP.

## Technical Scope

### Database Setup

- PostgreSQL 17+ installation and configuration
- Development and testing database environments
- Connection pooling and management
- Database migration framework setup

### Core Schema Design

- Users table with authentication fields
- Journal entries table with JSONB `raw_data` column
- Processed content table for AI analysis results
- Audit logging tables for compliance
- Proper indexing strategy for performance

### Schema Features

- JSONB support for flexible journal data structures
- UUID primary keys for scalability
- Timestamp tracking (created_at, updated_at)
- Foreign key relationships and constraints
- Database-level data validation

## Acceptance Criteria

### Functional Requirements

- [ ] PostgreSQL database successfully configured for development
- [ ] Core schema tables created and validated
- [ ] JSONB queries working correctly for journal data
- [ ] Database migrations system implemented
- [ ] Connection pooling configured and tested

### Technical Requirements

- [ ] All tables have proper primary keys (UUID)
- [ ] Foreign key relationships correctly established
- [ ] Indexes created for common query patterns
- [ ] Database connection pooling configured (25-50 connections)
- [ ] Migration rollback capability implemented

### Data Model Requirements

- [ ] User table supports OAuth and email authentication
- [ ] Journal entries accept any valid JSON structure
- [ ] Processed content linked to journal entries
- [ ] Audit trail for data modifications
- [ ] Proper data types and constraints

## Implementation Details

### Database Schema

```sql
-- Users table
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(255),
    auth_provider VARCHAR(50), -- 'google', 'github', 'email'
    auth_provider_id VARCHAR(255),
    preferences JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Journal entries table
CREATE TABLE journal_entries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    raw_data JSONB NOT NULL,
    entry_type VARCHAR(50) DEFAULT 'text',
    metadata JSONB DEFAULT '{}',
    processing_status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Processed content table
CREATE TABLE processed_content (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    journal_id UUID NOT NULL REFERENCES journal_entries(id) ON DELETE CASCADE,
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    task_type VARCHAR(100) NOT NULL,
    processed_data JSONB NOT NULL,
    confidence_score DECIMAL(3,2),
    ai_provider_info JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### Performance Indexes

```sql
-- Essential indexes for query performance
CREATE INDEX idx_journal_entries_user_id ON journal_entries(user_id);
CREATE INDEX idx_journal_entries_created_at ON journal_entries(created_at);
CREATE INDEX idx_processed_content_journal_id ON processed_content(journal_id);
CREATE INDEX idx_processed_content_task_type ON processed_content(task_type);

-- JSONB indexes for content queries
CREATE INDEX idx_journal_entries_raw_data_gin ON journal_entries USING GIN(raw_data);
```

### Migration Framework

- Use golang-migrate or similar tool
- Version-controlled migration files
- Up/down migration support
- Database state tracking

## Testing Strategy

### Unit Tests

- Database connection and pooling
- Schema validation queries
- JSONB operations and queries
- Migration up/down operations

### Integration Tests

- End-to-end database operations
- Transaction handling
- Concurrent access testing
- Performance benchmarks

## Configuration

### Environment Variables

```env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=englog
DB_USER=englog_user
DB_PASSWORD=secure_password
DB_MAX_CONNS=25
DB_MAX_IDLE_CONNS=10
DB_CONN_MAX_LIFETIME=1h
```

### Docker Compose Integration

```yaml
postgres:
  image: postgres:15-alpine
  environment:
    POSTGRES_DB: englog
    POSTGRES_USER: englog_user
    POSTGRES_PASSWORD: secure_password
  volumes:
    - postgres_data:/var/lib/postgresql/data
    - ./migrations:/docker-entrypoint-initdb.d
  ports:
    - "5432:5432"
```

## Migration Path from Phase 0

### Data Structure Mapping

- Phase 0 in-memory `Journal` struct → `journal_entries` table
- Simple sentiment → `processed_content` with `task_type='sentiment_analysis'`
- Add user association (currently prototype has no users)

### Migration Strategy

1. Create database schema
2. Implement repository pattern
3. Maintain dual storage during transition
4. Validate data consistency
5. Remove in-memory storage

## Dependencies

### External Dependencies

- PostgreSQL 17+ database server
- golang-migrate tool
- Database driver (lib/pq or pgx)
- Connection pooling library

### Internal Dependencies

- Environment configuration system
- Logging framework
- Error handling patterns

## Deliverables

1. **Database Schema:** Complete PostgreSQL schema with all tables
2. **Migration System:** Versioned migration framework setup
3. **Repository Layer:** Go database access layer with connection pooling
4. **Configuration:** Environment-based database configuration
5. **Documentation:** Schema documentation and setup instructions

## Definition of Done

- [ ] PostgreSQL database running in development environment
- [ ] All core tables created with proper relationships
- [ ] Database migrations working (up/down)
- [ ] Go repository layer implemented and tested
- [ ] JSONB operations validated with sample journal data
- [ ] Performance benchmarks completed
- [ ] Documentation updated with schema and setup instructions
- [ ] Code review completed and approved

---

**Estimated Timeline:** 5 days
**Risk Level:** Medium (database migration complexity)
**Blockers:** None
**Follow-up Tasks:** MVP-006 (User Management), MVP-007 (Journal Data Models)
