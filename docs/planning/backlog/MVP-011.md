# MVP-011: Redis Session Management

**Feature:** MVP-AUTH
**Priority:** P1 (High)
**Effort:** Small (2 days)
**Dependencies:** MVP-001 (PostgreSQL Database), MVP-003 (JWT Authentication)

## Objective

Implement Redis-based session management for secure user authentication, JWT token storage, rate limiting, and caching to improve performance and security.

## Technical Scope

### Session Management

- User session storage and retrieval
- JWT token storage with expiration
- Session invalidation and cleanup
- Refresh token management
- Multi-device session support

### Caching Strategy

- API response caching
- Database query result caching
- AI processing result caching
- User preferences caching
- Configuration data caching

### Rate Limiting

- Per-user request rate limiting
- Per-IP address rate limiting
- API endpoint-specific limits
- Sliding window implementation
- Rate limit status tracking

## Acceptance Criteria

### Session Management Requirements

- [ ] User sessions stored in Redis with TTL
- [ ] JWT tokens cached for quick validation
- [ ] Session cleanup on user logout
- [ ] Refresh token rotation working
- [ ] Multiple device sessions supported

### Caching Requirements

- [ ] Cache hit rate >70% for frequently accessed data
- [ ] Cache invalidation working correctly
- [ ] TTL-based cache expiration functional
- [ ] Memory usage stays within Redis limits
- [ ] Cache warming strategies implemented

### Rate Limiting Requirements

- [ ] Rate limits enforced per user and IP
- [ ] Sliding window algorithm implemented
- [ ] Rate limit headers returned in API responses
- [ ] Rate limit bypass for system operations
- [ ] Configurable rate limit thresholds

## Implementation Details

### Redis Session Store

```go
type RedisSessionStore struct {
    client  *redis.Client
    prefix  string
    ttl     time.Duration
    logger  *slog.Logger
    metrics *SessionMetrics
}

type Session struct {
    ID          string                 `json:"id"`
    UserID      string                 `json:"user_id"`
    DeviceID    string                 `json:"device_id"`
    IPAddress   string                 `json:"ip_address"`
    UserAgent   string                 `json:"user_agent"`
    CreatedAt   time.Time              `json:"created_at"`
    LastActivity time.Time             `json:"last_activity"`
    Metadata    map[string]any `json:"metadata"`
    ExpiresAt   time.Time              `json:"expires_at"`
}

type JWTTokenInfo struct {
    Token      string    `json:"token"`
    UserID     string    `json:"user_id"`
    IssuedAt   time.Time `json:"issued_at"`
    ExpiresAt  time.Time `json:"expires_at"`
    TokenType  string    `json:"token_type"` // "access" or "refresh"
    Revoked    bool      `json:"revoked"`
}

func NewRedisSessionStore(client *redis.Client, config SessionConfig) *RedisSessionStore {
    return &RedisSessionStore{
        client: client,
        prefix: config.KeyPrefix,
        ttl:    config.DefaultTTL,
        logger: slog.Default(),
    }
}

func (s *RedisSessionStore) CreateSession(ctx context.Context, session *Session) error {
    session.ID = generateSessionID()
    session.CreatedAt = time.Now()
    session.LastActivity = time.Now()
    session.ExpiresAt = time.Now().Add(s.ttl)

    sessionKey := s.sessionKey(session.ID)
    userSessionsKey := s.userSessionsKey(session.UserID)

    pipe := s.client.Pipeline()

    // Store session data
    sessionData, _ := json.Marshal(session)
    pipe.Set(ctx, sessionKey, sessionData, s.ttl)

    // Track user sessions
    pipe.SAdd(ctx, userSessionsKey, session.ID)
    pipe.Expire(ctx, userSessionsKey, s.ttl)

    // Update metrics
    s.metrics.ActiveSessions.Inc()

    _, err := pipe.Exec(ctx)
    if err != nil {
        return fmt.Errorf("failed to create session: %w", err)
    }

    s.logger.Info("Session created", "session_id", session.ID, "user_id", session.UserID)
    return nil
}

func (s *RedisSessionStore) GetSession(ctx context.Context, sessionID string) (*Session, error) {
    sessionKey := s.sessionKey(sessionID)

    data, err := s.client.Get(ctx, sessionKey).Result()
    if err == redis.Nil {
        return nil, ErrSessionNotFound
    }
    if err != nil {
        return nil, fmt.Errorf("failed to get session: %w", err)
    }

    var session Session
    if err := json.Unmarshal([]byte(data), &session); err != nil {
        return nil, fmt.Errorf("failed to unmarshal session: %w", err)
    }

    // Update last activity
    session.LastActivity = time.Now()
    go s.updateLastActivity(ctx, sessionID, session.LastActivity)

    return &session, nil
}

func (s *RedisSessionStore) InvalidateSession(ctx context.Context, sessionID string) error {
    sessionKey := s.sessionKey(sessionID)

    // Get session to find user ID
    session, err := s.GetSession(ctx, sessionID)
    if err != nil && err != ErrSessionNotFound {
        return err
    }

    pipe := s.client.Pipeline()

    // Remove session
    pipe.Del(ctx, sessionKey)

    // Remove from user sessions if we found the session
    if session != nil {
        userSessionsKey := s.userSessionsKey(session.UserID)
        pipe.SRem(ctx, userSessionsKey, sessionID)
    }

    // Update metrics
    s.metrics.ActiveSessions.Dec()

    _, err = pipe.Exec(ctx)
    if err != nil {
        return fmt.Errorf("failed to invalidate session: %w", err)
    }

    s.logger.Info("Session invalidated", "session_id", sessionID)
    return nil
}

func (s *RedisSessionStore) InvalidateUserSessions(ctx context.Context, userID string) error {
    userSessionsKey := s.userSessionsKey(userID)

    // Get all user sessions
    sessionIDs, err := s.client.SMembers(ctx, userSessionsKey).Result()
    if err != nil {
        return fmt.Errorf("failed to get user sessions: %w", err)
    }

    if len(sessionIDs) == 0 {
        return nil
    }

    pipe := s.client.Pipeline()

    // Remove all sessions
    for _, sessionID := range sessionIDs {
        sessionKey := s.sessionKey(sessionID)
        pipe.Del(ctx, sessionKey)
    }

    // Remove user sessions set
    pipe.Del(ctx, userSessionsKey)

    // Update metrics
    s.metrics.ActiveSessions.Sub(float64(len(sessionIDs)))

    _, err = pipe.Exec(ctx)
    if err != nil {
        return fmt.Errorf("failed to invalidate user sessions: %w", err)
    }

    s.logger.Info("All user sessions invalidated", "user_id", userID, "count", len(sessionIDs))
    return nil
}

func (s *RedisSessionStore) sessionKey(sessionID string) string {
    return fmt.Sprintf("%s:session:%s", s.prefix, sessionID)
}

func (s *RedisSessionStore) userSessionsKey(userID string) string {
    return fmt.Sprintf("%s:user_sessions:%s", s.prefix, userID)
}
```

### JWT Token Cache

```go
type JWTTokenCache struct {
    client  *redis.Client
    prefix  string
    logger  *slog.Logger
}

func NewJWTTokenCache(client *redis.Client, prefix string) *JWTTokenCache {
    return &JWTTokenCache{
        client: client,
        prefix: prefix,
        logger: slog.Default(),
    }
}

func (c *JWTTokenCache) StoreToken(ctx context.Context, tokenInfo *JWTTokenInfo) error {
    tokenKey := c.tokenKey(tokenInfo.Token[:20]) // Use first 20 chars as key
    blacklistKey := c.blacklistKey(tokenInfo.UserID)

    pipe := c.client.Pipeline()

    // Store token info
    tokenData, _ := json.Marshal(tokenInfo)
    ttl := time.Until(tokenInfo.ExpiresAt)
    pipe.Set(ctx, tokenKey, tokenData, ttl)

    // Track user tokens for blacklisting
    pipe.SAdd(ctx, blacklistKey, tokenInfo.Token[:20])
    pipe.Expire(ctx, blacklistKey, ttl)

    _, err := pipe.Exec(ctx)
    return err
}

func (c *JWTTokenCache) ValidateToken(ctx context.Context, token string) (*JWTTokenInfo, error) {
    tokenKey := c.tokenKey(token[:20])

    data, err := c.client.Get(ctx, tokenKey).Result()
    if err == redis.Nil {
        return nil, ErrTokenNotFound
    }
    if err != nil {
        return nil, err
    }

    var tokenInfo JWTTokenInfo
    if err := json.Unmarshal([]byte(data), &tokenInfo); err != nil {
        return nil, err
    }

    if tokenInfo.Revoked {
        return nil, ErrTokenRevoked
    }

    if time.Now().After(tokenInfo.ExpiresAt) {
        return nil, ErrTokenExpired
    }

    return &tokenInfo, nil
}

func (c *JWTTokenCache) RevokeToken(ctx context.Context, token string) error {
    tokenKey := c.tokenKey(token[:20])

    // Mark token as revoked
    return c.client.HSet(ctx, tokenKey, "revoked", true).Err()
}

func (c *JWTTokenCache) RevokeUserTokens(ctx context.Context, userID string) error {
    blacklistKey := c.blacklistKey(userID)

    // Get all user tokens
    tokens, err := c.client.SMembers(ctx, blacklistKey).Result()
    if err != nil {
        return err
    }

    pipe := c.client.Pipeline()

    // Revoke all tokens
    for _, tokenPrefix := range tokens {
        tokenKey := c.tokenKey(tokenPrefix)
        pipe.HSet(ctx, tokenKey, "revoked", true)
    }

    _, err = pipe.Exec(ctx)
    return err
}

func (c *JWTTokenCache) tokenKey(tokenPrefix string) string {
    return fmt.Sprintf("%s:token:%s", c.prefix, tokenPrefix)
}

func (c *JWTTokenCache) blacklistKey(userID string) string {
    return fmt.Sprintf("%s:user_tokens:%s", c.prefix, userID)
}
```

### Rate Limiter Implementation

```go
type RedisRateLimiter struct {
    client    *redis.Client
    prefix    string
    rules     map[string]RateRule
    logger    *slog.Logger
}

type RateRule struct {
    Requests int           `json:"requests"`
    Window   time.Duration `json:"window"`
    Burst    int           `json:"burst"`
}

type RateLimitResult struct {
    Allowed     bool          `json:"allowed"`
    Limit       int           `json:"limit"`
    Remaining   int           `json:"remaining"`
    ResetTime   time.Time     `json:"reset_time"`
    RetryAfter  time.Duration `json:"retry_after"`
}

func NewRedisRateLimiter(client *redis.Client, rules map[string]RateRule) *RedisRateLimiter {
    return &RedisRateLimiter{
        client: client,
        prefix: "rate_limit",
        rules:  rules,
        logger: slog.Default(),
    }
}

func (rl *RedisRateLimiter) Allow(ctx context.Context, identifier, ruleName string) (*RateLimitResult, error) {
    rule, exists := rl.rules[ruleName]
    if !exists {
        return &RateLimitResult{Allowed: true}, nil
    }

    return rl.checkSlidingWindow(ctx, identifier, ruleName, rule)
}

func (rl *RedisRateLimiter) checkSlidingWindow(ctx context.Context, identifier, ruleName string, rule RateRule) (*RateLimitResult, error) {
    key := fmt.Sprintf("%s:%s:%s", rl.prefix, ruleName, identifier)
    now := time.Now()
    windowStart := now.Add(-rule.Window)

    // Lua script for atomic sliding window check
    script := redis.NewScript(`
        local key = KEYS[1]
        local window_start = tonumber(ARGV[1])
        local now = tonumber(ARGV[2])
        local limit = tonumber(ARGV[3])
        local window_size = tonumber(ARGV[4])

        -- Remove expired entries
        redis.call('ZREMRANGEBYSCORE', key, 0, window_start)

        -- Count current requests
        local current = redis.call('ZCARD', key)

        if current < limit then
            -- Add current request
            redis.call('ZADD', key, now, now .. ':' .. math.random())
            redis.call('EXPIRE', key, window_size)
            return {1, limit - current - 1, limit}
        else
            return {0, 0, limit}
        end
    `)

    result, err := script.Run(ctx, rl.client, []string{key},
        windowStart.UnixNano(),
        now.UnixNano(),
        rule.Requests,
        int(rule.Window.Seconds())).Result()

    if err != nil {
        return nil, fmt.Errorf("rate limit check failed: %w", err)
    }

    resultSlice := result.([]any)
    allowed := resultSlice[0].(int64) == 1
    remaining := int(resultSlice[1].(int64))
    limit := int(resultSlice[2].(int64))

    resetTime := now.Add(rule.Window)
    var retryAfter time.Duration
    if !allowed {
        retryAfter = rule.Window
    }

    return &RateLimitResult{
        Allowed:    allowed,
        Limit:      limit,
        Remaining:  remaining,
        ResetTime:  resetTime,
        RetryAfter: retryAfter,
    }, nil
}
```

### Caching Service

```go
type CacheService struct {
    client      *redis.Client
    prefix      string
    defaultTTL  time.Duration
    maxKeySize  int
    serializer  Serializer
    logger      *slog.Logger
    metrics     *CacheMetrics
}

type CacheItem struct {
    Value     any       `json:"value"`
    CreatedAt time.Time `json:"created_at"`
    ExpiresAt time.Time `json:"expires_at"`
    Version   int       `json:"version"`
}

func NewCacheService(client *redis.Client, config CacheConfig) *CacheService {
    return &CacheService{
        client:     client,
        prefix:     config.Prefix,
        defaultTTL: config.DefaultTTL,
        maxKeySize: config.MaxKeySize,
        serializer: NewJSONSerializer(),
        logger:     slog.Default(),
    }
}

func (c *CacheService) Set(ctx context.Context, key string, value any, ttl time.Duration) error {
    if ttl == 0 {
        ttl = c.defaultTTL
    }

    cacheKey := c.buildKey(key)

    item := &CacheItem{
        Value:     value,
        CreatedAt: time.Now(),
        ExpiresAt: time.Now().Add(ttl),
        Version:   1,
    }

    data, err := c.serializer.Serialize(item)
    if err != nil {
        return fmt.Errorf("failed to serialize cache item: %w", err)
    }

    err = c.client.Set(ctx, cacheKey, data, ttl).Err()
    if err != nil {
        c.metrics.Errors.Inc()
        return fmt.Errorf("failed to set cache item: %w", err)
    }

    c.metrics.Sets.Inc()
    return nil
}

func (c *CacheService) Get(ctx context.Context, key string, dest any) error {
    cacheKey := c.buildKey(key)

    data, err := c.client.Get(ctx, cacheKey).Result()
    if err == redis.Nil {
        c.metrics.Misses.Inc()
        return ErrCacheKeyNotFound
    }
    if err != nil {
        c.metrics.Errors.Inc()
        return fmt.Errorf("failed to get cache item: %w", err)
    }

    var item CacheItem
    if err := c.serializer.Deserialize([]byte(data), &item); err != nil {
        c.metrics.Errors.Inc()
        return fmt.Errorf("failed to deserialize cache item: %w", err)
    }

    // Check expiration (double-check)
    if time.Now().After(item.ExpiresAt) {
        c.metrics.Misses.Inc()
        return ErrCacheKeyExpired
    }

    // Deserialize value into destination
    valueData, err := c.serializer.Serialize(item.Value)
    if err != nil {
        return err
    }

    if err := c.serializer.Deserialize(valueData, dest); err != nil {
        return fmt.Errorf("failed to deserialize cache value: %w", err)
    }

    c.metrics.Hits.Inc()
    return nil
}

func (c *CacheService) Delete(ctx context.Context, key string) error {
    cacheKey := c.buildKey(key)

    err := c.client.Del(ctx, cacheKey).Err()
    if err != nil {
        c.metrics.Errors.Inc()
        return fmt.Errorf("failed to delete cache item: %w", err)
    }

    c.metrics.Deletes.Inc()
    return nil
}

func (c *CacheService) InvalidatePattern(ctx context.Context, pattern string) error {
    cachePattern := c.buildKey(pattern)

    keys, err := c.client.Keys(ctx, cachePattern).Result()
    if err != nil {
        return fmt.Errorf("failed to find keys for pattern: %w", err)
    }

    if len(keys) == 0 {
        return nil
    }

    err = c.client.Del(ctx, keys...).Err()
    if err != nil {
        c.metrics.Errors.Inc()
        return fmt.Errorf("failed to delete cache keys: %w", err)
    }

    c.metrics.Deletes.Add(float64(len(keys)))
    return nil
}

func (c *CacheService) buildKey(key string) string {
    if len(key) > c.maxKeySize {
        // Hash long keys
        hasher := sha256.New()
        hasher.Write([]byte(key))
        key = hex.EncodeToString(hasher.Sum(nil))
    }

    return fmt.Sprintf("%s:%s", c.prefix, key)
}
```

## Testing Strategy

### Unit Tests

- Session CRUD operations
- JWT token caching and validation
- Rate limiting algorithm accuracy
- Cache hit/miss scenarios
- TTL and expiration handling

### Integration Tests

- Redis connection and failover
- Session invalidation across instances
- Rate limiting enforcement
- Cache invalidation patterns
- Performance under concurrent load

### Load Tests

- High-volume session operations
- Rate limiting effectiveness
- Cache performance with large datasets
- Memory usage monitoring
- Connection pooling efficiency

## Configuration

### Environment Variables

```env
# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_MAX_CONNECTIONS=100
REDIS_IDLE_TIMEOUT=300s

# Session Configuration
SESSION_TTL=24h
SESSION_KEY_PREFIX=englog
SESSION_CLEANUP_INTERVAL=1h

# Rate Limiting
RATE_LIMIT_USER_REQUESTS=100
RATE_LIMIT_USER_WINDOW=1m
RATE_LIMIT_IP_REQUESTS=1000
RATE_LIMIT_IP_WINDOW=1h

# Caching
CACHE_DEFAULT_TTL=15m
CACHE_MAX_KEY_SIZE=250
CACHE_MAX_MEMORY=512MB
```

### Rate Limit Rules

```go
var DefaultRateRules = map[string]RateRule{
    "user_api":         {Requests: 100, Window: time.Minute, Burst: 10},
    "user_auth":        {Requests: 5, Window: time.Minute, Burst: 2},
    "ip_global":        {Requests: 1000, Window: time.Hour, Burst: 50},
    "journal_create":   {Requests: 20, Window: time.Minute, Burst: 5},
    "ai_processing":    {Requests: 10, Window: time.Minute, Burst: 2},
}
```

## Monitoring and Metrics

### Prometheus Metrics

```go
var (
    SessionsActive = prometheus.NewGauge(prometheus.GaugeOpts{
        Name: "englog_sessions_active_total",
        Help: "Number of active user sessions",
    })

    CacheHitRatio = prometheus.NewGaugeVec(prometheus.GaugeOpts{
        Name: "englog_cache_hit_ratio",
        Help: "Cache hit ratio by cache type",
    }, []string{"cache_type"})

    RateLimitExceeded = prometheus.NewCounterVec(prometheus.CounterOpts{
        Name: "englog_rate_limit_exceeded_total",
        Help: "Number of rate limit violations",
    }, []string{"rule", "identifier_type"})

    RedisOperations = prometheus.NewCounterVec(prometheus.CounterOpts{
        Name: "englog_redis_operations_total",
        Help: "Number of Redis operations",
    }, []string{"operation", "status"})
)
```

### Health Checks

- Redis connection health
- Session store functionality
- Cache service availability
- Rate limiter accuracy
- Memory usage monitoring

## Migration Strategy

### Phase 0 to MVP

- Add Redis to infrastructure
- Migrate session storage from memory
- Implement token caching
- Add rate limiting middleware
- Enable response caching

### Data Migration

- No existing data to migrate (Phase 0 was in-memory)
- Configure Redis cluster for production
- Set up monitoring and alerting
- Implement backup strategies

## Dependencies

### External Dependencies

- Redis 7.0+
- Go Redis client (go-redis/redis)
- Prometheus metrics libraries
- JSON serialization libraries

### Internal Dependencies

- PostgreSQL Database (MVP-001)
- JWT Authentication (MVP-003)
- Configuration management
- Logging infrastructure

## Deliverables

1. **Session Store:** Redis-based session management
2. **Token Cache:** JWT token caching and validation
3. **Rate Limiter:** Sliding window rate limiting
4. **Cache Service:** General-purpose caching layer
5. **Middleware:** Session and rate limiting middleware
6. **Monitoring:** Metrics and health check implementation

## Definition of Done

- [ ] Redis session store functional with TTL
- [ ] JWT token caching working correctly
- [ ] Rate limiting enforced on all endpoints
- [ ] Cache hit rate >70% for repeated requests
- [ ] Session invalidation working properly
- [ ] Rate limit headers returned in responses
- [ ] Memory usage optimized and monitored
- [ ] Unit tests covering all components (90%+ coverage)
- [ ] Integration tests with Redis cluster
- [ ] Load testing validates performance targets
- [ ] Monitoring and alerting configured

---

**Estimated Timeline:** 2 days
**Risk Level:** Low (well-established technology)
**Blockers:** MVP-001 (PostgreSQL), MVP-003 (JWT Authentication)
**Follow-up Tasks:** MVP-012 (Session-based AI Processing)
