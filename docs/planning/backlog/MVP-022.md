# MVP-022: Docker Compose Production Setup

**Task ID:** MVP-022
**Feature Area:** MVP-DEVOPS
**Priority:** P1 (High)
**Effort Estimate:** 2 days
**Dependencies:** MVP-002 (Microservices Architecture Setup)

## Objective

Implement production-ready Docker containerization and orchestration setup with multi-stage builds, security hardening, service orchestration, and production environment configuration for reliable deployment of the EngLog system.

## Business Context

A robust containerization strategy enables consistent deployment across environments, simplified scaling, reduced infrastructure costs, and reliable service management. This is essential for production deployment and operational efficiency.

## Technical Requirements

### Core Components

1. **Multi-stage Docker Images**

   - Optimized build stages for Go services
   - Minimal runtime containers (Alpine/distroless)
   - Security-hardened configurations
   - Layer caching optimization

2. **Production Docker Compose**

   - Service orchestration with proper networking
   - Health checks and restart policies
   - Environment configuration management
   - Resource limits and constraints

3. **Container Security**

   - Non-root user execution
   - Read-only root filesystems
   - Security scanning integration
   - Secret management

4. **Service Configuration**
   - Production database setup
   - Redis configuration
   - Load balancer integration
   - SSL/TLS termination

## Implementation Specification

### Production Dockerfile (API Service)

```dockerfile
# Multi-stage build for API service
FROM golang:1.24-alpine AS builder

# Install security updates and required packages
RUN apk update && apk add --no-cache \
    git \
    ca-certificates \
    tzdata \
    && rm -rf /var/cache/apk/*

WORKDIR /app

# Copy dependency files
COPY go.mod go.sum ./
RUN go mod download

# Copy source code
COPY . .

# Build with optimizations
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
    -ldflags='-w -s -extldflags "-static"' \
    -a -installsuffix cgo \
    -o englog-api ./cmd/api

# Production stage
FROM alpine:latest

# Install CA certificates and timezone data
RUN apk --no-cache add ca-certificates tzdata \
    && rm -rf /var/cache/apk/*

# Create non-root user
RUN adduser -D -s /bin/sh -u 1001 appuser

WORKDIR /app

# Copy binary from builder
COPY --from=builder /app/englog-api .

# Set ownership
RUN chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1

EXPOSE 8080

ENTRYPOINT ["./englog-api"]
```

### Production Dockerfile (Worker Service)

```dockerfile
# Multi-stage build for Worker service
FROM golang:1.24-alpine AS builder

RUN apk update && apk add --no-cache \
    git \
    ca-certificates \
    tzdata \
    && rm -rf /var/cache/apk/*

WORKDIR /app

COPY go.mod go.sum ./
RUN go mod download

COPY . .

RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \
    -ldflags='-w -s -extldflags "-static"' \
    -a -installsuffix cgo \
    -o englog-worker ./cmd/worker

# Production stage
FROM alpine:latest

RUN apk --no-cache add ca-certificates tzdata \
    && rm -rf /var/cache/apk/*

RUN adduser -D -s /bin/sh -u 1001 appuser

WORKDIR /app

COPY --from=builder /app/englog-worker .

RUN chown -R appuser:appuser /app

USER appuser

# Worker health check (gRPC)
HEALTHCHECK --interval=60s --timeout=10s --start-period=10s --retries=3 \
    CMD ./englog-worker --health-check || exit 1

ENTRYPOINT ["./englog-worker"]
```

### Production Docker Compose

```yaml
# docker-compose.prod.yml
version: "3.8"

services:
  # Database
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME:-englog}
      POSTGRES_USER: ${DB_USER:-englog}
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    secrets:
      - db_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-englog}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "0.5"
    security_opt:
      - no-new-privileges:true

  # Redis Cache
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/etc/redis/redis.conf:ro
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.25"
    security_opt:
      - no-new-privileges:true

  # API Service
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
      target: production
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - PORT=8080
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-englog}
      - DB_USER=${DB_USER:-englog}
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_URL=redis://redis:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - JWT_SECRET_FILE=/run/secrets/jwt_secret
      - OPENAI_API_KEY_FILE=/run/secrets/openai_key
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=production
    secrets:
      - db_password
      - jwt_secret
      - openai_key
    volumes:
      - ./logs:/app/logs
    networks:
      - frontend
      - backend
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8080/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.5"
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp

  # Worker Service
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
      target: production
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-englog}
      - DB_USER=${DB_USER:-englog}
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - REDIS_URL=redis://redis:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - API_GRPC_URL=api:9090
      - OPENAI_API_KEY_FILE=/run/secrets/openai_key
      - AZURE_API_KEY_FILE=/run/secrets/azure_key
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=production
      - WORKER_CONCURRENCY=${WORKER_CONCURRENCY:-5}
    secrets:
      - db_password
      - openai_key
      - azure_key
    volumes:
      - ./logs:/app/logs
    networks:
      - backend
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 2G
          cpus: "1.5"
        reservations:
          memory: 1G
          cpus: "0.5"
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp

  # Load Balancer
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    depends_on:
      - api
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/ssl:/etc/nginx/ssl:ro
      - ./static:/usr/share/nginx/html:ro
      - nginx_logs:/var/log/nginx
    networks:
      - frontend
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost/health",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.25"
    security_opt:
      - no-new-privileges:true

  # Ollama (Optional AI Fallback)
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - backend
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
    profiles:
      - ollama

# Networks
networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.1.0/24
  backend:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.20.2.0/24

# Volumes
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  nginx_logs:
    driver: local

# Secrets
secrets:
  db_password:
    file: ./secrets/db_password.txt
  jwt_secret:
    file: ./secrets/jwt_secret.txt
  openai_key:
    file: ./secrets/openai_key.txt
  azure_key:
    file: ./secrets/azure_key.txt
```

### Nginx Configuration

```nginx
# config/nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream api_backend {
        least_conn;
        server api:8080 max_fails=3 fail_timeout=30s;
    }

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth:10m rate=5r/s;

    # Security headers
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload" always;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # API Server
    server {
        listen 80;
        server_name api.englog.com;

        # Redirect to HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name api.englog.com;

        ssl_certificate /etc/nginx/ssl/api.englog.com.crt;
        ssl_certificate_key /etc/nginx/ssl/api.englog.com.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;

        # API endpoints
        location /api/ {
            limit_req zone=api burst=20 nodelay;

            proxy_pass http://api_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;

            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # Auth endpoints with stricter rate limiting
        location /api/auth/ {
            limit_req zone=auth burst=10 nodelay;

            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Health check
        location /health {
            proxy_pass http://api_backend/health;
            access_log off;
        }

        # Static files
        location /static/ {
            root /usr/share/nginx/html;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }

    # Frontend Application
    server {
        listen 80;
        server_name englog.com www.englog.com;
        return 301 https://englog.com$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name www.englog.com;
        return 301 https://englog.com$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name englog.com;

        ssl_certificate /etc/nginx/ssl/englog.com.crt;
        ssl_certificate_key /etc/nginx/ssl/englog.com.key;
        ssl_protocols TLSv1.2 TLSv1.3;

        root /usr/share/nginx/html;
        index index.html;

        # SPA routing
        location / {
            try_files $uri $uri/ /index.html;
        }

        # API proxy
        location /api/ {
            proxy_pass https://api.englog.com;
        }

        # Static assets
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

### Environment Configuration

```bash
# .env.production
# Database Configuration
DB_NAME=englog_prod
DB_USER=englog_user
DB_HOST=postgres
DB_PORT=5432

# Redis Configuration
REDIS_PASSWORD=<secure-redis-password>

# Application Configuration
LOG_LEVEL=warn
ENVIRONMENT=production
PORT=8080

# Worker Configuration
WORKER_CONCURRENCY=5
MAX_PROCESSING_TIME=300

# AI Configuration
OLLAMA_URL=http://ollama:11434

# Security
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Monitoring
METRICS_ENABLED=true
TRACING_ENABLED=true
```

### Production Scripts

```bash
#!/bin/bash
# scripts/deploy-prod.sh
set -euo pipefail

echo "üöÄ Starting production deployment..."

# Check required environment files
if [[ ! -f .env.production ]]; then
    echo "‚ùå Missing .env.production file"
    exit 1
fi

# Check secrets directory
if [[ ! -d secrets ]]; then
    echo "‚ùå Missing secrets directory"
    exit 1
fi

# Required secrets
REQUIRED_SECRETS=(
    "secrets/db_password.txt"
    "secrets/jwt_secret.txt"
    "secrets/openai_key.txt"
)

for secret in "${REQUIRED_SECRETS[@]}"; do
    if [[ ! -f "$secret" ]]; then
        echo "‚ùå Missing required secret: $secret"
        exit 1
    fi
done

# Load environment
export $(cat .env.production | xargs)

# Build images
echo "üî® Building production images..."
docker-compose -f docker-compose.prod.yml build --no-cache

# Run security scan
echo "üîç Running security scan..."
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
    -v $(pwd):/app aquasec/trivy image --severity HIGH,CRITICAL \
    englog/api:latest

# Start services
echo "üé¨ Starting production services..."
docker-compose -f docker-compose.prod.yml up -d

# Wait for services to be healthy
echo "‚è≥ Waiting for services to be healthy..."
timeout 300 bash -c '
    until docker-compose -f docker-compose.prod.yml ps | grep -q "healthy"; do
        echo "Waiting for services..."
        sleep 10
    done
'

# Run health checks
echo "üè• Running health checks..."
./scripts/health-check-prod.sh

echo "‚úÖ Production deployment completed successfully!"
```

```bash
#!/bin/bash
# scripts/health-check-prod.sh
set -euo pipefail

API_URL="https://api.englog.com"
FRONTEND_URL="https://englog.com"

echo "üè• Running production health checks..."

# API Health Check
echo "Checking API health..."
HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$API_URL/health")
if [[ "$HTTP_CODE" != "200" ]]; then
    echo "‚ùå API health check failed (HTTP $HTTP_CODE)"
    exit 1
fi
echo "‚úÖ API is healthy"

# Database Connectivity
echo "Checking database connectivity..."
DB_CHECK=$(curl -s "$API_URL/health/db" | jq -r '.status')
if [[ "$DB_CHECK" != "healthy" ]]; then
    echo "‚ùå Database connectivity check failed"
    exit 1
fi
echo "‚úÖ Database is connected"

# Redis Connectivity
echo "Checking Redis connectivity..."
REDIS_CHECK=$(curl -s "$API_URL/health/redis" | jq -r '.status')
if [[ "$REDIS_CHECK" != "healthy" ]]; then
    echo "‚ùå Redis connectivity check failed"
    exit 1
fi
echo "‚úÖ Redis is connected"

# Frontend Accessibility
echo "Checking frontend..."
FRONTEND_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$FRONTEND_URL")
if [[ "$FRONTEND_CODE" != "200" ]]; then
    echo "‚ùå Frontend check failed (HTTP $FRONTEND_CODE)"
    exit 1
fi
echo "‚úÖ Frontend is accessible"

# Performance Test
echo "Running basic performance test..."
RESPONSE_TIME=$(curl -s -o /dev/null -w "%{time_total}" "$API_URL/health")
if (( $(echo "$RESPONSE_TIME > 1.0" | bc -l) )); then
    echo "‚ö†Ô∏è  API response time is slow: ${RESPONSE_TIME}s"
else
    echo "‚úÖ API response time is good: ${RESPONSE_TIME}s"
fi

echo "üéâ All health checks passed!"
```

### Security Configuration

```dockerfile
# Dockerfile.security-scanner
FROM aquasec/trivy:latest

WORKDIR /app

COPY docker-compose.prod.yml .

# Scan for vulnerabilities
RUN trivy config --severity HIGH,CRITICAL .

# Scan images
RUN trivy image --severity HIGH,CRITICAL englog/api:latest
RUN trivy image --severity HIGH,CRITICAL englog/worker:latest
```

```yaml
# docker-compose.security.yml
version: "3.8"

services:
  security-scanner:
    build:
      context: .
      dockerfile: Dockerfile.security-scanner
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - .:/app
    command: ["trivy", "fs", "--severity", "HIGH,CRITICAL", "/app"]
```

### Monitoring Integration

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: "englog-api"
    static_configs:
      - targets: ["api:8080"]
    metrics_path: "/metrics"
    scrape_interval: 15s

  - job_name: "postgres-exporter"
    static_configs:
      - targets: ["postgres-exporter:9187"]

  - job_name: "redis-exporter"
    static_configs:
      - targets: ["redis-exporter:9121"]

  - job_name: "nginx-exporter"
    static_configs:
      - targets: ["nginx-exporter:9113"]
```

## Acceptance Criteria

### Core Requirements

- [ ] Multi-stage Docker builds with size optimization (< 50MB final images)
- [ ] Production Docker Compose with all services properly configured
- [ ] Container security hardening (non-root users, read-only filesystems)
- [ ] Service health checks and restart policies
- [ ] Load balancer configuration with SSL termination
- [ ] Secret management with Docker secrets
- [ ] Resource limits and monitoring integration
- [ ] Security scanning integration with vulnerability detection

### Performance Requirements

- [ ] Container startup time < 30 seconds
- [ ] Service discovery and networking functional
- [ ] Load balancer distributing traffic correctly
- [ ] SSL/TLS termination working with valid certificates
- [ ] Resource utilization within defined limits

### Security Requirements

- [ ] No containers running as root
- [ ] Read-only root filesystems where possible
- [ ] Network segmentation (frontend/backend networks)
- [ ] Secret management without plain text passwords
- [ ] Security scanning passing with no HIGH/CRITICAL vulnerabilities
- [ ] Rate limiting configured and functional

### Quality Requirements

- [ ] Comprehensive deployment scripts with error handling
- [ ] Health check scripts validating all services
- [ ] Documentation for production deployment process
- [ ] Rollback procedures documented and tested
- [ ] Monitoring integration working with metrics collection

## Task Dependencies

- **Prerequisite:** MVP-002 (Microservices Architecture Setup)
- **Enables:** MVP-023 (CI/CD Pipeline Implementation)
- **Enables:** MVP-024 (Monitoring & Observability)

## Definition of Done

- [ ] Production-ready Docker images built and tested
- [ ] Docker Compose configuration validated in staging environment
- [ ] Security scanning integrated and passing
- [ ] Load balancer configuration tested with SSL
- [ ] Deployment scripts working and documented
- [ ] Health checks validating all service functionality
- [ ] Performance benchmarks meeting requirements
- [ ] Documentation complete for production deployment
- [ ] Rollback procedures documented and tested
- [ ] Team training completed on deployment process

## Notes

- Container images should be scanned for vulnerabilities before deployment
- Use Docker secrets for sensitive configuration data
- Implement proper logging and monitoring from day one
- Consider using Docker Swarm or Kubernetes for true production scaling
- SSL certificates should be managed through proper CA or Let's Encrypt
- Resource limits should be based on actual usage patterns and load testing
